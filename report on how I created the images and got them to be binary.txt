I created the images using GIMP and exporting them as PGM files type ASCII, then I created an R program which essentially 
iterates through the each file in the dataset folder adding them to a dataframe, I then created a 18x18 matrix which takes 
the values in the dataframe and adds then to a matrix, I then use a nested for loop iterating through each which iterates through
each column and row in the matrix updating the values of each of the cells in the matrix to be equal to 1 if the currentcell value 
is greater than 128, and updated cells that values were less than 128 to be equal to 0 in the end to create an ascii image.

code:
{library(readr)
 library(utile.tables)
  
  
  
  data_files <- list.files(path = "ai_dataset
  
  for(index in 1:length(data_files)){
    working_folder <- "ai_dataset/"
    current_file <- data_files[index]
    
    current_file_path <- paste(working_folder, current_file, sep = "")
    
    pgmFile <- read_lines(file = current_file_path, skip = 4)
    imageMatrix <- matrix(pgmFile, nrow = 18, ncol = 18)
    
    for(row in 1:nrow(imageMatrix)) 
    {
      for(col in 1:ncol(imageMatrix)) 
      {
        if(imageMatrix[row,col] < 128)
        {
          imageMatrix[row,col] = 1
        }
        else
        {
          imageMatrix[row,col] = 0
        }
      }
    }
    
    imageMatrix <- t(imageMatrix)
    
    write.table(imageMatrix, file = paste("updated_ai_dataset/", data_files[index], sep = ""), row.names = FALSE, col.names = FALSE)
    
  }
}

I finally changed the file types of these images using a program I downloaded from the internet called bulk extension changer to change
the file types of everything in the folder to go from .PGM to csv.