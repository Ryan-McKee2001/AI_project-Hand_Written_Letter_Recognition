---
title: "Assignment 2: Feature Engineering, Statistical Analysis and Machine Learning"
author: "Ryan McKee (40294886)"
output:
  pdf_document:
     includes: 
         in_header: "preamble.tex"
  html_notebook: default
  html_document:
    df_print: paged
---

## Introduction

The overall objective of this project is to create A.I that will be able to recognize letters in the set {a,b,c,d,e,f,g,h,i,j}, as well as recognize smiley faces, sad faces and exclamation marks. In this part of the assignment(assignment 2) My goals are to create a data set of hand drawn letters, smiley faces, sad faces and exclamation marks. Then perform feature engineering on these images to calculate features such as how many black pixels exist in the image and aspect ratio. Then perform statistical analysis of the data sets using methods of statistical inference such as using histograms and finally for this assignment implement and evaluate some machine learning models that perform classification on the data set.

# Section 1
In section the goal is to create the ai data set which will be used throughout the entirety of this coursework. To do this I created my data set images for letters in set {a,...,j}, smiley faces, sad faces and exclamation marks using GIMP with images of 18x18 pixels and exporting these images as PGM files type ASCII. This file type stored the values of pixels on 324 separate lines, each line having a value of 255 representing a white pixel or 0 representing a black pixel this file type allows me to create a script to convert these images to csv matrix representation of the .pgm image that can easily be analysed later in this assignment. In order to make these conversions I created an R script as shown below. This R script stores each of the files in the pgm image folder as a list. I then looped through this list reading the pixel values of each of the element and changing the elements value in the matrix to 0 if the element value is greater or equal to 128, or if less than I changed the value of that element in the matrix to be equal to 1. I then used write.table to write the updated matrix's to new csv file's in a folder that contains the updated .csv data set and using the gsub function in the paste function for getting the file path I changed the file extensions for the file names to go from .pgm to .csv.

```{r section 1 code, echo=TRUE}
  {library(readr)
  library(utile.tables)
  
  
  # * To change the folder that contains the .pgm files
  # Just change the path in list.files() belowe to be equal
  # to the file path of the folder, and change the working_folder
  # to be equal to the file path + / *
  data_files <- list.files(path = "./dataset2/pmg_images_dataset")
  working_folder <- "./dataset2/pmg_images_dataset/"
  
  for(index in 1:length(data_files)){
    
    current_file <- data_files[index]
    
    current_file_path <- paste(working_folder, current_file, sep = "")
    
    pgmFile <- read_lines(file = current_file_path, skip = 4)
    imageMatrix <- matrix(pgmFile, nrow = 18, ncol = 18)
    
    for(row in 1:nrow(imageMatrix)) 
    {
      for(col in 1:ncol(imageMatrix)) 
      {
        if(imageMatrix[row,col] < 128)
        {
          imageMatrix[row,col] = 1
        }
        else
        {
          imageMatrix[row,col] = 0
        }
      }
    }
    
    imageMatrix <- t(imageMatrix)
    
    # * To change the folder that the updated dataset gets created in just change the first argument in the paste function to the file path for updated folder + / *
    write.table(imageMatrix, file = paste("./dataset2/csv_images_dataset", gsub('.pgm', '.csv', data_files[index]), sep = ""), col.names = F, row.names = F, sep = ",", quote = FALSE)
    
  }
  
  print("csv dataset has been successfully created.")
}
```

### Sources:
* https://www.youtube.com/watch?v=4-uWgh5kDSc - used this video to show me how to iterate through files in the pgm directory.


# Section 2
The objective of section 2 is to calculate an array of features describing each of the image matrix's created in part one. To do this I created 18 functions for each of the calculations Each function took a parameter relating to the calculation that the function was carrying out, for example all 16 features that were being calculated took an image matrix as a parameter while the first two function that where getting the label and the index of the image matrix took the image matrix file's name so that I could take a sub string from from the file name. I used these 18 functions in a for loop that iterated through a list of all the csv image files from the image directory. Every iteration through this for loop creates an 18x18 matrix which reads the current file data into the matrix. I then created an 18x1 matrix which stores the values returned from the calculation functions inside it. Finally I append the feature calculations matrix to a csv file so each row stores a the calculations for a new image file.

The 18th function in my section 2 was the custom function, For this function I had a few ideas for how to implement this but decided that this function should check the center 6x6 sub set of the image matrix and calculate the percentage of black pixels from the image that exist in this area. I think this feature may be useful as it could provide clear distinction between items in the data-set that are likely to have very little pixels in the center 6x6 like an 'a' would probably no pixels in the center 6x6 if it is drawn big enough while a letter like an 'i' would probably have a high percentage of black pixels in this area.

When working on section 3 I noticed that my histograms where off for eyes as I was getting 3 non letters that had more than 1 eye as sad faces and smiley faces should not have any especially the ones that where in my data set as I checked I realized that raster and clump was recognizing an enclosed area in the image as an eye because the mouth of the image was reaching the bottom border of the page, to fix this I added 2 to each row and column in my raster image after which I got new updated results which were correct.




```{r section 2 code, eval=FALSE}
source('./section2_code.R')
```

### sources
* https://stackoverflow.com/questions/58302969/how-would-i-inverse-the-binary-digits-0-and-1-of-a-matrix-in-r - I used this to figure out how to inverse a matrix for my eyes function
* https://www.youtube.com/watch?v=j5a0jTc9S10&list=PL3KnTfyhrIlcudeMemKd6rZFGDWyK23vx&index=11 - I used this video for motivation
* https://www.rdocumentation.org/packages/raster/versions/3.4-5/topics/clump - I used this documentation to figure out how to use the raster and clump function for both my eye's and connected areas function


# Section 3
The objective of this section is to perform statistical analyses of the feature data created in from my data-set in section 2 to allow for important distinctions between handwritten symbols from my data-set. 

Shown below is a table containing the feature calculations for each of the images which will be used for image analysis for the rest of the assignment.
```{r Feature calculation table, echo=FALSE, paged.print=TRUE}
{
  library(readr)
  library(ggplot2)
  library(tidyverse)
  library(matrixStats) # matrix calculation library - colMedians
  library(knitr) 
  
  # This is the setup code for section 3 it just read the feature calculations into a data.frame
  mydata <- read.csv("40294886_features.csv", row.names = NULL)
  calculated_features <- data.frame(mydata)
  calculated_features_col_names <- c("Label", "Index", "nr_pix", "rows_with_1", "cols_with_1",
    "rows_with_3p", "cols_with_3p", "aspect_ratio", "neigh_1",
    "no_neigh_above","no_neigh_below","no_neigh_left","no_neigh_right",
    "no_neigh_horiz", "no_neigh_vert","connected_areas","eyes","custom")
  colnames(calculated_features) <- calculated_features_col_names
  mydata[ , 3:18] <- as.numeric(mydata[ , 3,18])
  
  letters_calculated_features <- calculated_features[1:80,]
    non_letters_calculated_features<- calculated_features[81:140,]
    letters_calculated_features[, 18] <- as.numeric(letters_calculated_features[ , 18])
    non_letters_calculated_features[ , 18] <- as.numeric(non_letters_calculated_features[ , 18])
    
    
    # # get the mean of each column
    letters_mean <- c(colMeans(letters_calculated_features[ , 3:18]))
    non_letters_mean <- c(colMeans(non_letters_calculated_features[ , 3:18]))
  
    # get the medians of each column
    letters_median <- c(colMedians(as.matrix(letters_calculated_features[ , 3:18])))
    non_letters_median <- c(colMedians(as.matrix(non_letters_calculated_features[ , 3:18])))
  
    #get the standard deviation of each column
    letters_sd <- colSds(as.matrix(letters_calculated_features[, 3:18][sapply(letters_calculated_features[ , 3:18 ], is.numeric)]))
    non_letters_sd <- colSds(as.matrix(non_letters_calculated_features[ , 3:18][sapply(non_letters_calculated_features[ , 3:18], is.numeric)]))
    
  
  # printing feature calculations
   table = matrix(NA, nrow = 16, ncol = 0)
  rownames(table) = c("nr_pix", "rows_with_1", "cols_with_1",
                                     "rows_with_3p", "cols_with_3p", "aspect_ratio", "neigh_1",
                                     "no_neigh_above","no_neigh_below","no_neigh_left","no_neigh_right",
                                     "no_neigh_horiz", "no_neigh_vert","connected_areas","eyes","custom")
  
  table <- cbind(table, letters_mean)
  table <- cbind(table, non_letters_mean)
  table <- cbind(table, letters_median)
  table <- cbind(table, non_letters_median)
  table <- cbind(table, letters_sd)
  table <- cbind(table, non_letters_sd)
  
  features_table<-kable(table, caption = "This table shows the letter and non letters mean, median and standard deviation for each of the feature calculations")

print(features_table)
}
```
### Sources
* https://www.youtube.com/watch?v=6ruNR3VDfyo - used this video to teach me how to use knitr kable

## Section 3.1
In this subsection I have created 6 histograms histograms for the first six features over the full set of the 140 items in the data-set to show the distribution of values for each of these features. I did this using three ggplot functions and then plotting the graphs objects created using this function.
```{r distribution histograms, echo=FALSE}
{
  library(readr)
  library(ggplot2)
  library(tidyverse)
  # matrix stats has functions for getting colMedian and standard deviation
  library(matrixStats)
  library(knitr) # using this to make a table for my report.
  
  # This section of code read in the feature calculations created in sections 2 code adds
  # csv seperated values to columns, and new lines create a new row in a data frame
  mydata <- read.csv("40294886_features.csv", row.names = NULL)
  calculated_features <- data.frame(mydata)
  calculated_features_col_names <- c("Label", "Index", "nr_pix", "rows_with_1", "cols_with_1",
    "rows_with_3p", "cols_with_3p", "aspect_ratio", "neigh_1",
    "no_neigh_above","no_neigh_below","no_neigh_left","no_neigh_right",
    "no_neigh_horiz", "no_neigh_vert","connected_areas","eyes","custom")
  colnames(calculated_features) <- calculated_features_col_names

  # had to change custom function to numeric class as for some reason it was character
  mydata[ , 3:18] <- as.numeric(mydata[ , 3,18])
  
  
  
  # 3.1

 # plots histograms for the values for each of the features for each of the images
  histograms_3_1 <- function(){
    nr_pix_hist <- ggplot(data = calculated_features, aes(nr_pix))+
    geom_histogram(binwidth = 2, fill = "grey")+
    theme_bw() +
    labs(title = "Number of pixels histogram",
         x = "Number of pixels",
         y = "Frequency")
    
    rows_with_1_hist <- ggplot(data = calculated_features, aes(rows_with_1)) +
             geom_histogram(binwidth = 1, fill = "red") +
             theme_bw() +
             labs(title = "Rows with 1 pixel histogram",
                  x = "Number of rows with 1 pixel",
                  y = "Frequency")

    cols_with_1_hist <- calculated_features %>%
      ggplot(aes(cols_with_1))+
      geom_histogram(binwidth = 1, fill = "red")+
      theme_bw() +
      labs(title = "Columns with 1 histogram",
           x = "Number of columns with 1",
           y = "Frequency")

    rows_with_3p_hist <- calculated_features %>%
      ggplot(aes(rows_with_3p))+
      geom_histogram(binwidth = 1, fill = "blue")+
      theme_bw() +
      labs(title = "Rows with 3 pixels of more histogram",
           x = "Number of rows with 3 pixels or more",
           y = "Frequency")

    cols_with_3p_hist <- calculated_features %>%
      ggplot(aes(cols_with_3p))+
      geom_histogram(binwidth = 1, fill = "blue")+
      theme_bw() +
      labs(title = "Columns with 3 pixels of more histogram",
           x = "Number of columns with 3 pixels or more",
           y = "Frequency")

    aspect_ratio_hist <- calculated_features %>%
      ggplot(aes(aspect_ratio))+
      geom_histogram(binwidth = 0.1, fill = "orange")+
      theme_bw() +
      labs(title = "Aspect ratio histogram",
           x = "Aspect ratios",
           y = "Frequency")
    
    print(nr_pix_hist)
    print(rows_with_1_hist)
    print(cols_with_1_hist)
    print(rows_with_3p_hist)
    print(cols_with_3p_hist)
    print(aspect_ratio_hist)
  }
  
  histograms_3_1()

}
```
### Number of pixels histogram
nr_pix histogram seems to have a slightly random distribution although it has 4 clear peaks. The 0-20  pixels group contains the first peak. This group has around 20 images due to the pixel number being so low I think it is safe to assume that these are the i and ! The next group is 20-50 there is 2 peaks I assume that this group represents the letters with a vast majority of letters being around 30 pixels. After this group there is just random clusters of bars between 50-100 pixels I believe that these images as smiley faces and sad faces with maybe some thicker letters are in this group too. 

### Rows with 1 pixel
rows_with_1 histogram seems to have a right skewed shape with some drops in frequency of some rows with 1 pixel numbers. The highest peak appears where number of rows wih 1 pixel is equal to 0 I believe that the frequency is high because there is multiple letters and potentially non letters which are in this group some letters I think would be in the 0 rows_with_1 group would be a and c. After this there is a group from 1-5 rows with 1 I believe this group i comprised of b, e, d, e, h the final group is contains 5-13 pixels these are likely f, i, j, smiley face, sad face and exclamation marks.

### Columns with 1 histogram
In this histogram there is over 60 images in this histograms contain 0 columns with only 1, I believe his group comprises of a, b, c, d, e, g, h, i, !, as for the group groups. As for the remaining images there are distributed over the rest of the groups in the graph.

### Rows with 3 pixels or more histogram
This histogram has a peak at the first group 0 rows with 3 pixels or more this group most likely contains i, ! image's with some other images maybe j's in that group as well as there are 27 images that make up this group as for the other groups. group 1- 5 is likely contains letters like a, b, c, d, e, h. With f,j, smiley face and sad faces being likely to have 1 or 2 rows with 3 pixels or more. As for images in the group 6-10 they are most likely more letters like a, b, d, e, g which are drawn thicker.

### Columns with 3 pixels or more histogram
This histogram is right skewed with the highest peak being at the 0 columns group of columns with 3 pixels or more with 25 images in this group This 0 group likely contains some smiley faces and sad faces. as for images in the 1-5 group this group probably contains letters, exclamation marks and faces with a long nose and eyes. I believe that most of the letters like a, b, c, d, e, g, h would only have 2 columns with 3 pixels or higher unless they are drawn thicker.

### Aspect ratio histogram
Again like many of the histograms the biggest peak is at the first group between 0.0 and 0.2 aspect ratio. and then after there is a bell like shape with 3 peaks in between. I believe that letters would have aspect ratios in the group 0 to 0.7 aspect ratio, with i and j maybe having lower aspect ratios around 0.1 to 0.3. the higher aspect ratios are probably causing by smiley faces and sad faces.

### Sources
* https://www.rdocumentation.org/packages/ggplot2/versions/3.3.5 - used this documentation to teach me ggplot


## Section 3.2
In this section the aim is to gain useful summary statistics like the mean, median and standard deviation of both the letters and non letters. To do this I continued writing the script I had created in section 3.1 using the calculated_features data.frame I had read in from the calculated features csv file I created in section 2 I split the data up into letters calculated features and a non letters calculated feature data frame. Then I carried out calculations on each of the features in these data frames to do this I use a function I found from r documentation apart of the library matrixStats to get the column median, mean, and standard deviation then using these statistics I created 3 ggplot comparison histograms to allow for easy visualisation for means, medians and stadards deviations of each feature for letters and their non letter counterparts.

```{r echo=FALSE, results='axis', stdout=TRUE, fig.width=14,fig.height=11}
source("section3_code.R")

```
### Letter and non letters mean comparison
Based on the bar chart presented above comparing feature means of non letters and letters some of the most interesting features I believe that could be used to differentiate appear to be cols_with_1 which for letters has a mean of 1 while non letters has a mean of 4. Connected areas is another feature with a mean that could differentiate between a letter and a non letter with letters having a mean of 1.5 while non letters having a mean around 3.5. From the graph it if a image has eyes it is guaranteed that it is a letter. no_neigh_horiz, no_neigh_vert, rows_with_1 and rows_with_3p as well are interseting as they show the mean to be on average around 2-4 higher for letters compared to non letters. custom and nr_pix also seem to be features good for differentiating with a mean of around 7-8 higher for letters compared to non letters.

### Letters and non letters medians
Like in the mean comparison graph aspect ratio has a similar mean and standard deviation is non letters having a slightly higher value by average. Interestingly cols_with 1 median is 0 for letters in this graph while the median for non is around 4. This appears to confirm my suspision stated in section 3.2 that although some letters have columns with with 1 like some f's, and j's majority have no columns with only 1. while faces have multiple so this could be a good feature for differentiation. cols_with_3p has the same value for letter and non leeter. while connected areas has a big difference. eyes has medians of 0 for both telling me that more than half of the letters have no eyes. The neigh functions also have differences in mean of around 4 apart from no_neigh right and rows_with_1 has a much higher median of around 4 for letters. while nr_pix and rows_with_3p also have very small differences.

### cols_with_1
Again aspect ratio has a similar looking differentiation between letter and non letter values, while cols_with_1 has a 0 deviation since there are barely any letters that have columns with 1 pixel. custom has a high differentiation in standard deviation cols with 3p also does. as for the neighs, neigh 1 no_neigh horiz and no_neighvert are the only ones with high differentiations between them. rows_with_1 and rows with 3p have a higher differentiation for letters.

### conclusion
Based on the results presented above I believe that 3 features stand out as the best to differentiate between letters and none letters. The first one eyes as this feature guarentees that an image is a letter if it has a value anything greater than 0. The next feature is cols_with_1 as when the value for cols_with_1 is anything greater than 0 it makes it highly likely that the image is a non letter. And the final feature and the final feature is no_neigh_horiz as it has a higher mean and median and standard devaition for letters.

### Sources
* https://www.rdocumentation.org/packages/matrixStats/versions/0.1.5/topics/matrixStats-package - A library with function for getting colMedians and col standard devations.
* https://www.youtube.com/watch?v=-bPjGgD5bZQ - Used this video to teach me how to do a grouped bar chart

## Section 3.3
In this section I created 16 ggplot histogram's which compare's the distributions of the features for letters and non letters with grey bars representing letters and non letters being represented by green bars. 
```{r Letter vs non letter comparison histograms, echo=FALSE}
source("section3_code.R")
```
Based on the graphs presented above it tells me that based on the distribution comparisons between the letter and non letter features the features that are best at distinction between letter and non letter are aspect ratio as the distribution heavily leans towards the higher towards the end group from 1-1.5, there is also a good amount of non letters with a 0 - 0.25 aspect ratio compared to letters which is distributed mainly between 0.3-1. Eye's also is useful as as it tell us that 40 letters have eyes, this means that when a letter has eyes it guarantees that an image is a letter. Columns with one distribution chart also shows that it is a good feature for working out distribution as you can guarentee that an image is a non letter if the cols with 1 is greater than 6. 

## Section 3.4
In this section I investigate the linear association between features. I did this by using the cor.test function on comparisons of each of the features values then returning the p value and cor values for each of these cor.tests to a cor_matrix and a p_value_data frame. I then iterate through the top 4 correlation values in the cor_matrix where the p_values in the same position as the current cor_matrix value is less than 0.05 meaning that the correlation between the comparison is statistically significant. I then plot a distribution graph and a linear association graph for the comparisons.

```{r linear regression graphs, echo=TRUE,cache = TRUE}
source("section3_code.R")
```
From the graphs presented above the highest correlation comparisons which are statistically significant are no_neigh_above-no_neigh_below, no_neigh_above-no_neigh_vert, no_neigh_below-no_neigh_vert and nr_pix-rows_with_3p. no_neigh_above and no_neigh_below correlate as when creating any of the images typically there is a lot of straight horizontal lines so typically that would mean that there would be no pixels above or below the pixels in the horizontal line. no_neigh_above-no neigh vertically correlate as no_neigh_vert just means that the pixel above and below are white 0's which is likely as no_neigh_above is already 0. No_neigh_vert and no_neigh_below is for the same reason as the previous comparison as theres a high probability of no_neigh_vert being 0 as no_neigh_below is already 0 and finally nr_pix and rows_with_3p are likely highly correlated as images that have thicker width's and heights have a higher number of pixels and typically these thicker drawn images are more likely to have more rows_with_3p.

### Source
* https://www.youtube.com/watch?v=66z_MRwtFJM

# Section 4
## Section 4.1
In this section I just fit a multiple regression model to predict aspect_ratio using the lm function. In the formula I used custom + no_neigh_above + no_neigh_below as these where the features that most strongly correlated with aspect ratio from the cor.tests that I done in section 3.4. I then printed the summary of the object created by my lm function.
```{r multiple regression model, echo=FALSE}
source("section4_code.R")
```

### Source
* http://www.sthda.com/english/articles/40-regression-analysis/168-multiple-linear-regression-in-r/ - multiple linear regression model

## Section 4.2


## Section 4.3
In this section I created 3 functions which the first function checks if if the median for features nr_pixels, aspect_ratio and neigh_1 for all rows in calculated_features is less than the medians for the subsets of the calculated features letters, faces and exclamation marks. If the subset median for each of these features is greater than the over all median for these features a 1 is assigned to the correlating index in a data frame then printed.

```{r}
source("section4_code.R")
```


## Section 4.4

